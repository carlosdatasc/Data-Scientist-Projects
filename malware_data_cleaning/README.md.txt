# ğŸ§¹ Malware Dataset â€“ Data Cleaning, EDA & Preprocessing

## ğŸ“– Overview

I used a **public dataset** containing information about technological devices and their characteristics, indicating whether they are infected with malware or not.

I chose this dataset because it is provided in `.csv` format, which realistically represents how raw data is often delivered in professional environments. Many educational datasets come already cleaned, while this one requires real **data cleaning**, **exploratory data analysis (EDA)**, and **preprocessing** â€” offering excellent practice for understanding each stage of the data pipeline.

---

## ğŸ§° Tech Stack

The libraries used throughout this project include:

**Python**, **Pandas**, **NumPy**, **Matplotlib**, **Seaborn**, **os**, and **Scikit-learn**.

---

## âš™ï¸ Project Steps

### 1. ğŸ§¹ Cleaning

1. Categorization of columns
2. Handling missing values
3. Removing highly unbalanced binary columns
4. Replacing inconsistent values
5. Fixing incorrect data types
6. Creating new derived columns based on existing ones

### 2. ğŸ“Š Exploratory Data Analysis (EDA)

1. Identifying outliers
2. Removing outliers
3. Analyzing correlations between variables
4. Creating scatterplots to evaluate variable relationships
5. Reviewing categorical variables vs. target variable
6. Analyzing variance of numerical variables by target

### 3. âš™ï¸ Preprocessing

1. Encoding categorical columns
2. Applying **MinMaxScaler**
3. Creating dummy variables with **get_dummies()**

---

## ğŸš€ How to Run

Follow these steps to set up and run the project locally:

```bash
# 1) Clone the repository
git clone https://github.com/your-username/malware-data-cleaning.git
cd malware-data-cleaning

# 2) Create & activate a virtual environment
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

# 3) Install dependencies
pip install -r requirements.txt

```

---

## ğŸ”’ Disclaimer

This project uses **public and non-sensitive data**.

Any sensitive or proprietary data must be anonymized before sharing.